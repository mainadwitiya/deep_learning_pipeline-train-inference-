{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "file_path='/home/daisy/mydrive/web-dev/deep_learning_pipeline-train-inference-/training_controller/apis/configs/tf2/centernet_hourglass104_1024x1024_coco17_tpu-32.config'\n",
    "path_2='/home/daisy/mydrive/web-dev/deep_learning_pipeline-train-inference-/kk.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "train_input_config",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-012835494566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mproto_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtext_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpipeline_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_input_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_map_path\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"123/label_map.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mpipeline_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_resizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_shape_resizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mpipeline_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_resizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_shape_resizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: train_input_config"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "from google.protobuf import text_format\n",
    "from object_detection.protos import pipeline_pb2\n",
    "\n",
    "\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "print(pipeline_config)\n",
    "with tf.io.gfile.GFile(file_path, \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config) \n",
    "pipeline_config.train_input_config.label_map_path= \"123/label_map.txt\"\n",
    "pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.height = 300                                                                                                                                                                                          \n",
    "pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.width = 300\n",
    "\n",
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(path_2, \"wb\") as f:                                                                                                                                                                                                                       \n",
    "    f.write(config_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_arguments():                                                                                                                                                                                                                                                \n",
    "#     parser = argparse.ArgumentParser(description='')                                                                                                                                                                                                                  \n",
    "#     parser.add_argument('pipeline')                                                                                                                                                                                                                                   \n",
    "#     parser.add_argument('output')                                                                                                                                                                                                                                     \n",
    "#     return parser.parse_args()                                                                                                                                                                                                                                        \n",
    "\n",
    "\n",
    "def main():                                                                                                                                                                                                                                                           \n",
    "    args = parse_arguments()                                                                                                                                                                                                                                          \n",
    "                                                                                                                                                                                                             \n",
    "\n",
    "    with tf.gfile.GFile(args.pipeline, \"r\") as f:                                                                                                                                                                                                                     \n",
    "        proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "        text_format.Merge(proto_str, pipeline_config)                                                                                                                                                                                                                 \n",
    "\n",
    "    pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.height = 300                                                                                                                                                                                          \n",
    "    pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.width = 300                                                                                                                                                                                           \n",
    "\n",
    "    config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "    with tf.gfile.Open(args.output, \"wb\") as f:                                                                                                                                                                                                                       \n",
    "        f.write(config_text)                                                                                                                                                                                                                                          \n",
    "\n",
    "\n",
    "if __name__ == '__main__':                                                                                                                                                                                                                                            \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import config_util\n",
    "\n",
    "pipeline_config = config_util.get_configs_from_pipeline_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model {\n",
       "  center_net {\n",
       "    num_classes: 90\n",
       "    feature_extractor {\n",
       "      type: \"hourglass_104\"\n",
       "      channel_means: 104.01361846923828\n",
       "      channel_means: 114.03422546386719\n",
       "      channel_means: 119.91659545898438\n",
       "      channel_stds: 73.60276794433594\n",
       "      channel_stds: 69.89082336425781\n",
       "      channel_stds: 70.91507720947266\n",
       "      bgr_ordering: true\n",
       "    }\n",
       "    image_resizer {\n",
       "      keep_aspect_ratio_resizer {\n",
       "        min_dimension: 1024\n",
       "        max_dimension: 1024\n",
       "        pad_to_max_dimension: true\n",
       "      }\n",
       "    }\n",
       "    object_detection_task {\n",
       "      task_loss_weight: 1.0\n",
       "      offset_loss_weight: 1.0\n",
       "      scale_loss_weight: 0.10000000149011612\n",
       "      localization_loss {\n",
       "        l1_localization_loss {\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    object_center_params {\n",
       "      object_center_loss_weight: 1.0\n",
       "      classification_loss {\n",
       "        penalty_reduced_logistic_focal_loss {\n",
       "          alpha: 2.0\n",
       "          beta: 4.0\n",
       "        }\n",
       "      }\n",
       "      min_box_overlap_iou: 0.699999988079071\n",
       "      max_box_predictions: 100\n",
       "    }\n",
       "  }\n",
       "}\n",
       "train_config {\n",
       "  batch_size: 128\n",
       "  data_augmentation_options {\n",
       "    random_horizontal_flip {\n",
       "    }\n",
       "  }\n",
       "  data_augmentation_options {\n",
       "    random_adjust_hue {\n",
       "    }\n",
       "  }\n",
       "  data_augmentation_options {\n",
       "    random_adjust_contrast {\n",
       "    }\n",
       "  }\n",
       "  data_augmentation_options {\n",
       "    random_adjust_saturation {\n",
       "    }\n",
       "  }\n",
       "  data_augmentation_options {\n",
       "    random_adjust_brightness {\n",
       "    }\n",
       "  }\n",
       "  data_augmentation_options {\n",
       "    random_square_crop_by_scale {\n",
       "      scale_min: 0.6000000238418579\n",
       "      scale_max: 1.2999999523162842\n",
       "    }\n",
       "  }\n",
       "  optimizer {\n",
       "    adam_optimizer {\n",
       "      learning_rate {\n",
       "        cosine_decay_learning_rate {\n",
       "          learning_rate_base: 0.0010000000474974513\n",
       "          total_steps: 50000\n",
       "          warmup_learning_rate: 0.0002500000118743628\n",
       "          warmup_steps: 5000\n",
       "        }\n",
       "      }\n",
       "      epsilon: 1.0000000116860974e-07\n",
       "    }\n",
       "    use_moving_average: false\n",
       "  }\n",
       "  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED/ckpt-1\"\n",
       "  num_steps: 50000\n",
       "  max_number_of_boxes: 100\n",
       "  unpad_groundtruth_tensors: false\n",
       "  fine_tune_checkpoint_type: \"detection\"\n",
       "  fine_tune_checkpoint_version: V2\n",
       "}\n",
       "train_input_reader {\n",
       "  label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
       "  tf_record_input_reader {\n",
       "    input_path: \"PATH_TO_BE_CONFIGURED/train2017-?????-of-00256.tfrecord\"\n",
       "  }\n",
       "}\n",
       "eval_config {\n",
       "  metrics_set: \"coco_detection_metrics\"\n",
       "  use_moving_averages: false\n",
       "  batch_size: 1\n",
       "}\n",
       "eval_input_reader {\n",
       "  label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
       "  shuffle: false\n",
       "  num_epochs: 1\n",
       "  tf_record_input_reader {\n",
       "    input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'gfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-70cd41e437e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-70cd41e437e8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpipeline_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainEvalPipelineConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mproto_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtext_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'gfile'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "from google.protobuf import text_format\n",
    "from object_detection.protos import pipeline_pb2\n",
    "\n",
    "\n",
    "# def parse_arguments():                                                                                                                                                                                                                                                \n",
    "#     parser = argparse.ArgumentParser(description='')                                                                                                                                                                                                                  \n",
    "#     parser.add_argument('pipeline')                                                                                                                                                                                                                                   \n",
    "#     parser.add_argument('output')                                                                                                                                                                                                                                     \n",
    "#     return parser.parse_args()                                                                                                                                                                                                                                        \n",
    "\n",
    "\n",
    "def main():\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    file_path='/home/daisy/mydrive/web-dev/deep_learning_pipeline-train-inference-/training_controller/apis/configs/tf2/centernet_hourglass104_1024x1024_coco17_tpu-32.config'                                                                                                                                                                                                                                         \n",
    "    pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n",
    "\n",
    "    with tf.gfile.GFile(args.pipeline, \"r\") as f:                                                                                                                                                                                                                     \n",
    "        proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "        text_format.Merge(proto_str, pipeline_config)                                                                                                                                                                                                                 \n",
    "\n",
    "    pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.height = 300                                                                                                                                                                                          \n",
    "    pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.width = 300                                                                                                                                                                                           \n",
    "\n",
    "    config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "    with tf.gfile.Open(args.output, \"wb\") as f:                                                                                                                                                                                                                       \n",
    "        f.write(config_text)                                                                                                                                                                                                                                          \n",
    "\n",
    "\n",
    "if __name__ == '__main__':                                                                                                                                                                                                                                            \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-ae70657cc7c2>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-ae70657cc7c2>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    cd $TOOL_DIR\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "TOOL_DIR=tool/tf-models/research\n",
    "\n",
    "(\n",
    "   cd $TOOL_DIR\n",
    "   protoc object_detection/protos/*.proto --python_out=.\n",
    ")\n",
    "\n",
    "export PYTHONPATH=$PYTHONPATH:$TOOL_DIR:$TOOL_DIR/slim\n",
    "\n",
    "python3 edit_pipeline.py pipeline.config pipeline_new.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'train_input_reader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-2bca7930ef26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_input_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_record_input_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/tensorflow/models/data/train100.record'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'train_input_reader'"
     ]
    }
   ],
   "source": [
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[0] = '/tensorflow/models/data/train100.record'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
